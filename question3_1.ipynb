{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import palettable\n",
    "import math\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./data/用于问题23的数据.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"white\", palette=\"husl\")\n",
    "plt.figure(dpi=1000)\n",
    "x = np.array(df['5 or more tries (X)'])\n",
    "y = np.array(df['percentage_proc'])\n",
    "\n",
    "z1 = np.polyfit(x, y, 1)              # 曲线拟合，返回值为多项式的各项系数\n",
    "p1 = np.poly1d(z1)                    # 返回值为多项式的表达式，也就是函数式子\n",
    "print(p1)\n",
    "y_pred = p1(x)                        # 根据函数的多项式表达式，求解 y\n",
    "# print(np.polyval(p1, 29))             根据多项式求解特定 x 对应的 y 值\n",
    "# print(np.polyval(z1, 29))             根据多项式求解特定 x 对应的 y 值\n",
    "\n",
    "plot1 = plt.plot(x, y, '.b', label='original values')\n",
    "plot2 = plt.plot(x, y_pred, 'r', label='fit values')\n",
    "plt.title('')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.legend(loc=3, borderaxespad=0., bbox_to_anchor=(0, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"5 or more tries (X)\"] = df['5 tries'] + df['6 tries'] + df['7 or more tries (X)']\n",
    "sns.set()\n",
    "sns.lmplot(data=df, x='5 or more tries (X)', y='percentage_proc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"white\", palette=\"husl\")\n",
    "plt.figure(dpi=1000)\n",
    "x = np.array(df['4 or less tries (X)'])\n",
    "y = np.array(df['percentage_proc'])\n",
    "\n",
    "z1 = np.polyfit(x, y, 1)              # 曲线拟合，返回值为多项式的各项系数\n",
    "p1 = np.poly1d(z1)                    # 返回值为多项式的表达式，也就是函数式子\n",
    "print(p1)\n",
    "y_pred = p1(x)                        # 根据函数的多项式表达式，求解 y\n",
    "# print(np.polyval(p1, 29))             根据多项式求解特定 x 对应的 y 值\n",
    "# print(np.polyval(z1, 29))             根据多项式求解特定 x 对应的 y 值\n",
    "\n",
    "plot1 = plt.plot(x, y, '.b', label='original values')\n",
    "plot2 = plt.plot(x, y_pred, 'r', label='fit values')\n",
    "plt.title('')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.legend(loc=3, borderaxespad=0., bbox_to_anchor=(0, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"4 or less tries (X)\"] = df['1 try'] + df['2 tries'] + df['3 tries'] + df['4 tries']\n",
    "sns.set()\n",
    "sns.lmplot(data=df, x='4 or less tries (X)', y='percentage_proc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,[\"4 or less tries (X)\", \"5 or more tries (X)\", \"percentage_proc\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 难度定义，越难指标越高\n",
    "# 4次以上、困难模式占比  --> 成本型\n",
    "# 5次以上              --> 效益型\n",
    "# 重复字母个数          --> 效益型\n",
    "# 单词常见程度          --> 成本型\n",
    "X = df.loc[:,[\"4 or less tries (X)\", \"5 or more tries (X)\", \"percentage_proc\",\n",
    "              'number of repeated letters', 'word commonness', ]].values\n",
    "X[:, 2] = X[:, 2] * 1000\n",
    "# X[:, 3] = np.exp(X[:, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(X[:, 2]) - min(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据规范化\n",
    "X[:, 0] = (max(X[:, 0]) - X[:, 0]) / (max(X[:, 0]) - min(X[:, 0]))\n",
    "X[:, 1] = (X[:, 1] - min(X[:, 1])) / (max(X[:, 1]) - min(X[:, 1]))\n",
    "X[:, 2] = (max(X[:, 2]) - X[:, 2]) / (max(X[:, 2]) - min(X[:, 2]))\n",
    "X[:, 3] = (X[:, 3] - min(X[:, 3])) / (max(X[:, 3]) - min(X[:, 3]))\n",
    "X[:, 4] = (max(X[:, 4]) - X[:, 4]) / (max(X[:, 4]) - min(X[:, 4]))\n",
    "# X[:, 3] = (max(X[:, 3]) - X[:, 3]) / (max(X[:, 3]) - min(X[:, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[11, 0] = 0\n",
    "X[11, 1] = 0\n",
    "X[23, 2] = 0\n",
    "# X[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化矩阵\n",
    "norm_X = X / np.sum(X, axis=0)\n",
    "norm_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(norm_X[:,3] == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有元素为0，需要加一个极小值，使其大于0\n",
    "norm_X = norm_X + 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算信息熵\n",
    "entropy = -np.sum(norm_X * np.log(norm_X), axis=0) / np.log(norm_X.shape[0])\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算权重\n",
    "m = len(entropy)\n",
    "sum_entropy = np.sum(entropy)\n",
    "weight = (1 - entropy) / (m - sum_entropy)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.matmul(X, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"difficulty factor\"] = z\n",
    "# df['norm_4-'] = X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lmplot(data=df, x='4 or less tries (X)', y='difficulty factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lmplot(data=df, x='5 or more tries (X)', y='difficulty factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "def l1_weighted_dist(x, y, w):\n",
    "    return np.sum(w * np.abs(x - y))\n",
    "\n",
    "def weighted_euclidean_distance(x, y, w):\n",
    "    return np.sqrt(np.sum(w * (x - y)**2))\n",
    "\n",
    "def kmeans(X, k, w, max_iter=100):\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Step 1: Initialize k centroids randomly\n",
    "    centroids = X[np.random.choice(n_samples, k, replace=False), :]\n",
    "\n",
    "    # Step 2: Repeat until convergence or max iterations reached\n",
    "    for i in range(max_iter):\n",
    "        # Step 2.1: Assign samples to nearest centroid\n",
    "        cluster_labels = np.zeros(n_samples)\n",
    "        for j, x in enumerate(X):\n",
    "            dists = [weighted_euclidean_distance(x, c, w) for c in centroids]\n",
    "            cluster_labels[j] = np.argmin(dists)\n",
    "\n",
    "        # Step 2.2: Update centroids\n",
    "        for c in range(k):\n",
    "            X_cluster = X[cluster_labels == c, :]\n",
    "            if len(X_cluster) > 0:\n",
    "                centroids[c, :] = np.average(X_cluster, axis=0)\n",
    "\n",
    "    return centroids, cluster_labels\n",
    "\n",
    "# Run k-means clustering with weighted L1 distance\n",
    "centroids, labels = kmeans(X, k=3, w=weight)\n",
    "\n",
    "# Print the centroids and cluster labels\n",
    "print(\"Centroids:\\n\", centroids)\n",
    "print(\"Cluster labels:\\n\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_k = 10  # 最大簇数\n",
    "sse = []\n",
    "silhouette_coeffs = []\n",
    "for k in range(1, max_k + 1):\n",
    "    labels, centers = kmeans(X, k, weight)\n",
    "    # sse.append(np.sum([(X[i] - centers[int(labels[i])]) ** 2 for i in range(len(X))]))\n",
    "    if k > 1:\n",
    "        silhouette_coeffs.append(np.mean([silhouette_coefficient(X[i], labels[i], centers, weight) for i in range(len(X))]))\n",
    "\n",
    "# 绘制肘部图\n",
    "# plt.plot(range(1, max_k + 1), sse)\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('SSE')\n",
    "# plt.title('Elbow Method')\n",
    "# plt.show()\n",
    "\n",
    "# 绘制轮廓系数\n",
    "plt.plot(range(2, max_k + 1), silhouette_coeffs)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义肘部法则函数\n",
    "def kmeans_sse(X, k, w):\n",
    "    centroids, clusters = kmeans(X, k, w)\n",
    "    sse = np.sum([np.sum((X[clusters==i] - centroids[i])**2) for i in range(k)])\n",
    "    return sse\n",
    "\n",
    "ks = range(1, 10) # 尝试的不同簇数\n",
    "sses = [kmeans_sse(X, k, weight) for k in ks] # 计算每个簇数对应的SSE值\n",
    "plt.plot(ks, sses, '-o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Sum of Squared Errors (SSE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = labels\n",
    "df.to_excel('data/data for 3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/data for 3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['difficulty factor'][df[df['labels'].apply(lambda x: x == 0)].index].mean())\n",
    "print(df['difficulty factor'][df[df['labels'].apply(lambda x: x == 1)].index].mean())\n",
    "print(df['difficulty factor'][df[df['labels'].apply(lambda x: x == 2)].index].mean())\n",
    "# print(df['difficulty factor'][df[df['labels'].apply(lambda x: x == 3)].index].mean())\n",
    "# print(df['difficulty factor'][df[df['labels'].apply(lambda x: x == 4)].index].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.violinplot(data=df, x=\"labels\", y=\"difficulty factor\", split=True)\n",
    "sns.set_theme(style=\"white\", palette=\"pastel\")\n",
    "plt.figure(dpi=1000)\n",
    "sns.boxplot(data=df, x=\"labels\", y=\"difficulty factor\", \n",
    "            showfliers=False, color='white', boxprops = {'color':'red',#箱子外框\n",
    "           'facecolor':'pink'},\n",
    "           showmeans=True,#箱图显示均值，\n",
    "            meanline=True,#显示均值线\n",
    "            meanprops = {'linestyle':'--','color':'red'},\n",
    "            palette=palettable.tableau.TrafficLight_9.mpl_colors,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算SSE\n",
    "# sse = []\n",
    "# for k in range(1, 11):\n",
    "#     centroids, labels = kmeans(X, k, w=weight)\n",
    "#     score = silhouette_score(X, labels)\n",
    "#     sse.append(score)\n",
    "\n",
    "# # 绘制肘部图\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# plt.plot(range(1, 11), sse)\n",
    "# plt.xlabel(\"Number of clusters\")\n",
    "# plt.ylabel(\"SSE\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = silhouette_score(norm_X, labels)\n",
    "print(f\"n_clusters={n_clusters}, silhouette score={score:.4f}\")\n",
    "\n",
    "score = calinski_harabasz_score(norm_X, labels)\n",
    "print(f\"n_clusters={n_clusters}, Calinski-Harabasz score={score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "data_pca = pca.fit_transform(norm_X)\n",
    "\n",
    "# 使用3D散点图可视化聚类结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(data_pca[:,0], data_pca[:,1], data_pca[:,2], c=labels)\n",
    "plt.show()\n",
    "\n",
    "# # 使用3D散点图可视化聚类结果\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(X[:,0], X[:,1], X[:,2], c=labels)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "data_tsne = tsne.fit_transform(X)\n",
    "\n",
    "\n",
    "# 使用散点图可视化聚类结果\n",
    "plt.scatter(data_tsne[:,0], data_tsne[:,1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['word freq'] = df['word freq']*100000\n",
    "# df['word freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 并不影响lgbm的性能\n",
    "# df['letter1 freq'] = df['letter1 freq'] * 10\n",
    "# df['letter2 freq'] = df['letter2 freq'] * 10\n",
    "# df['letter3 freq'] = df['letter3 freq'] * 10\n",
    "# df['letter4 freq'] = df['letter4 freq'] * 10\n",
    "# df['letter5 freq'] = df['letter5 freq'] * 10\n",
    "# df['5 letters freq'] = df['5 letters freq'] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label2\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label2'][df[\"difficulty factor\"].apply(lambda x: x>0.8)] = 4\n",
    "df['label2'][df[\"difficulty factor\"].apply(lambda x: x>0.6 and x<=0.8)] = 3\n",
    "df['label2'][df[\"difficulty factor\"].apply(lambda x: x>0.4 and x<=0.6)] = 2\n",
    "df['label2'][df[\"difficulty factor\"].apply(lambda x: x>0.2 and x<=0.4)] = 1\n",
    "df[\"label2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label2'].apply(lambda x: x == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_series = df['labels']\n",
    "y_series = y_series.astype('int64')\n",
    "# y_series = feature_df['Accident Level']\n",
    "# feature = ['Contest number',\n",
    "#        'Number of  reported results', \n",
    "#        'number of repeated letters', 'number of vowels',\n",
    "#        'number of common consonants', 'word commonness',\n",
    "#        'number of common letters', 'LetterFreq1', 'LetterFreq2', 'LetterFreq3',\n",
    "#        'LetterFreq4', 'LetterFreq5', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h',\n",
    "#        'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
    "#        'w', 'x', 'y', 'z', 'cl_included', '1 is vowel',\n",
    "#        '2 is vowel', '3 is vowel', '4 is vowel', '5 is vowel']\n",
    "feature = [\n",
    "       'number of repeated letters', \n",
    "       'number of common consonants', 'word commonness',\n",
    "       'number of common letters']\n",
    "part_category = df[feature]\n",
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(x_df, y_series, test_size=0.2, random_state=0, stratify=y_series)\n",
    "X1_train, X1_valid, Y1_train, Y1_valid = train_test_split(part_category, y_series, test_size=0.2, random_state=0, stratify=y_series)\n",
    "\n",
    "# lgb_train = lgb.Dataset(X_train, Y_train)\n",
    "lgb1_train = lgb.Dataset(X1_train, Y1_train)\n",
    "lgb1_valid = lgb.Dataset(X1_valid, Y1_valid, reference=lgb1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting' : 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_error',\n",
    "    'num_leaves': 100,\n",
    "    'feature_fraction': 1.0,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'bagging_freq': 0,\n",
    "    'min_child_samples': 5,\n",
    "    'verbose': -1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'learning rate': 0.01,\n",
    "    'lambda_l1': 7,\n",
    "    'max_depth':7\n",
    "\n",
    "}\n",
    "gbm_ac1 = lgb.train(params,\n",
    "            lgb1_train,\n",
    "            num_boost_round=100,\n",
    "            valid_sets=lgb1_valid,\n",
    "            early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X1_train.loc[:, ['number of repeated letters']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", palette=\"husl\")\n",
    "plt.figure(dpi=1000)\n",
    "ac_label = ['medium','easy','difficult']\n",
    "explainer = shap.TreeExplainer(model=gbm_ac1)\n",
    "# explainer = shap.TreeExplainer(model=xgbboost1)\n",
    "shap_values_ac = explainer.shap_values(X=X1_train)\n",
    "shap.summary_plot(shap_values=shap_values_ac, features=X1_train, feature_names=X1_train.columns, plot_type=\"bar\", max_display=30, class_names=ac_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['is_repetitive',\n",
    "#        'repetitive numbers', 'number of vowels', 'number of consonants',\n",
    "#        'word freq', 'number of common letter', 'letter1 freq', 'letter2 freq',\n",
    "#        'letter3 freq', 'letter4 freq', 'letter5 freq', '5 letters freq', 'a',\n",
    "#        'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o',\n",
    "#        'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'cl_included']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eerie = np.array([[620, 14836, 2, 4, 1, 8.564364327276781, 5, 0.09971195391262602,\n",
    "                     0.09971195391262602, 0.07220355256841095, 0.05804128660585694,\n",
    "                     0.09971195391262602, 0, 0, 0, 0, 3, 0, 0, 0,\n",
    "                     1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
    "                     1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pred = gbm_ac1.predict(X_eerie)\n",
    "label = np.argmax(single_pred)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extra = np.array([df[feature].iloc[6, :]])\n",
    "single_pred = gbm_ac1.predict(X_extra)\n",
    "label = np.argmax(single_pred)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df.loc[:, ['percentage_proc', '5 or more tries (X)', '4 or less tries (X)']]\n",
    "scaler_X = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# 设置聚类个数\n",
    "n_clusters = 3\n",
    "\n",
    "# 实例化KMeans聚类器\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "\n",
    "# 训练聚类器\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# 获取聚类结果\n",
    "labels = kmeans.labels_\n",
    "\n",
    "score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "print(f\"n_clusters={n_clusters}, silhouette score={score:.4f}\")\n",
    "\n",
    "score = calinski_harabasz_score(X_scaled, kmeans.labels_)\n",
    "print(f\"n_clusters={n_clusters}, Calinski-Harabasz score={score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1 try'] = df['1 try'] / df['percentage']\n",
    "df['2 tries'] = df['2 tries'] / df['percentage']\n",
    "df['3 tries'] = df['3 tries'] / df['percentage']\n",
    "df['4 tries'] = df['4 tries'] / df['percentage']\n",
    "df['5 tries'] = df['5 tries'] / df['percentage']\n",
    "df['6 tries'] = df['6 tries'] / df['percentage']\n",
    "df['7 or more tries (X)'] = df['7 or more tries (X)'] / df['percentage']\n",
    "df['7 or more tries (X)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_ba = df[\"1 try\"].sum()/len(df)/100\n",
    "s1 = df[\"1 try\"].apply(lambda x: (x - x1_ba)**2).sum()/(len(df)-1)/100\n",
    "v1 = math.sqrt(s1)/x1_ba\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_ba = df[\"2 tries\"].sum()/len(df)/100\n",
    "s2 = df[\"2 tries\"].apply(lambda x: (x - x2_ba)**2).sum()/(len(df)-1)/100\n",
    "v2 = math.sqrt(s2)/x2_ba\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_ba = df[\"3 tries\"].sum()/len(df)/100\n",
    "s3 = df[\"3 tries\"].apply(lambda x: (x - x3_ba)**2).sum()/(len(df)-1)/100\n",
    "v3 = math.sqrt(s3)/x3_ba\n",
    "v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4_ba = df[\"4 tries\"].sum()/len(df)/100\n",
    "s4 = df[\"4 tries\"].apply(lambda x: (x - x4_ba)**2).sum()/(len(df)-1)/100\n",
    "v4 = math.sqrt(s4)/x4_ba\n",
    "v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5_ba = df[\"5 tries\"].sum()/len(df)/100\n",
    "s5 = df[\"5 tries\"].apply(lambda x: (x - x5_ba)**2).sum()/(len(df)-1)/100\n",
    "v5 = math.sqrt(s5)/x5_ba\n",
    "v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x6_ba = df[\"6 tries\"].sum()/len(df)/100\n",
    "s6 = df[\"6 tries\"].apply(lambda x: (x - x6_ba)**2).sum()/(len(df)-1)/100\n",
    "v6 = math.sqrt(s6)/x6_ba\n",
    "v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x7_ba = df[\"7 or more tries (X)\"].sum()/len(df)/100\n",
    "s7 = df[\"7 or more tries (X)\"].apply(lambda x: (x - x7_ba)**2).sum()/(len(df)-1)/100\n",
    "v7 = math.sqrt(s7)/x7_ba\n",
    "v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [v2, v3, v4, v5, v6, v7]\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [0,0,0,0,0,0]\n",
    "for i in range(6):\n",
    "    w[i] = v[i]/sum(v)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./data/用于问题23的数据.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ['percentage_proc', '1 try',\n",
    "       '2 tries', '3 tries', '4 tries', '5 tries', '6 tries',\n",
    "       '7 or more tries (X)']]\n",
    "# X['percentage_proc'] = X['percentage_proc']*1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_X = StandardScaler()\n",
    "scaler_X = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置聚类个数\n",
    "n_clusters = 3\n",
    "\n",
    "# 实例化KMeans聚类器\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "\n",
    "# 训练聚类器\n",
    "kmeans.fit(X)\n",
    "\n",
    "# 获取聚类结果\n",
    "labels = kmeans.labels_\n",
    "\n",
    "\n",
    "\n",
    "score = silhouette_score(X, kmeans.labels_)\n",
    "print(f\"n_clusters={n_clusters}, silhouette score={score:.4f}\")\n",
    "\n",
    "score = calinski_harabasz_score(X, kmeans.labels_)\n",
    "print(f\"n_clusters={n_clusters}, Calinski-Harabasz score={score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算SSE\n",
    "# sns.set_theme(style=\"white\", palette=\"husl\")\n",
    "plt.figure(dpi=1000)\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# 绘制肘部图\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(range(1, 11), sse)\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", palette=\"husl\")\n",
    "plt.figure(dpi=1000)\n",
    "silhouette_scores = []\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000, random_state=0)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# 绘制轮廓系数图\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(range(2, 11), silhouette_scores)\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "data_pca = pca.fit_transform(X)\n",
    "\n",
    "# 使用3D散点图可视化聚类结果\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(data_pca[:,0], data_pca[:,1], data_pca[:,2], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "data_tsne = tsne.fit_transform(X)\n",
    "\n",
    "\n",
    "# 使用散点图可视化聚类结果\n",
    "plt.scatter(data_tsne[:,0], data_tsne[:,1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['percentage_proc', '1 try',\n",
    "       '2 tries', '3 tries', '4 tries', '5 tries', '6 tries',\n",
    "       '7 or more tries (X)', 'label']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fdac869eac949bb6d4e229a322d967a241b652318876d012b0ded5e5a35e33d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
